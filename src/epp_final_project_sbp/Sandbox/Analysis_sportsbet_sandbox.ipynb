{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all information needed to scrape data from football-data.co.uk\n",
    "\n",
    "beginning_url = \"https://www.football-data.co.uk/\"\n",
    "years = [\n",
    "    \"2223\",\n",
    "    \"2122\",\n",
    "    \"2021\",\n",
    "    \"1920\",\n",
    "    \"1819\",\n",
    "    \"1718\",\n",
    "    \"1617\",\n",
    "    \"1516\",\n",
    "    \"1415\",\n",
    "    \"1314\",\n",
    "    \"1213\",\n",
    "    \"1213\",\n",
    "    \"1112\",\n",
    "]\n",
    "Leagues = {\n",
    "    \"PL\": {\n",
    "        \"Foldername\": \"PL_data\",\n",
    "        \"Leaguetag\": \"PL\",\n",
    "        \"Leaguename\": \"E0\",\n",
    "        \"Leagueurl\": \"https://www.football-data.co.uk/englandm.php\",\n",
    "    },\n",
    "    \"BL\": {\n",
    "        \"Foldername\": \"BL_data\",\n",
    "        \"Leaguetag\": \"BL\",\n",
    "        \"Leaguename\": \"D1\",\n",
    "        \"Leagueurl\": \"https://www.football-data.co.uk/germanym.php\",\n",
    "    },\n",
    "    \"PD\": {\n",
    "        \"Foldername\": \"PD_data\",\n",
    "        \"Leaguetag\": \"PD\",\n",
    "        \"Leaguename\": \"SP1\",\n",
    "        \"Leagueurl\": \"https://www.football-data.co.uk/spainm.php\",\n",
    "    },\n",
    "    \"SA\": {\n",
    "        \"Foldername\": \"SA_data\",\n",
    "        \"Leaguetag\": \"SA\",\n",
    "        \"Leaguename\": \"I1\",\n",
    "        \"Leagueurl\": \"https://www.football-data.co.uk/italym.php\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "considered_features = [\n",
    "    \"league\",\n",
    "    \"kick_off_time\",\n",
    "    \"HomeTeam\",\n",
    "    \"AwayTeam\",\n",
    "    \"full_time_goals_hometeam\",\n",
    "    \"full_time_goals_awayteam\",\n",
    "    \"full_time_result\",\n",
    "    \"half_time_goals_hometeam\",\n",
    "    \"half_time_goals_awayteam\",\n",
    "    \"half_time_result\",\n",
    "    \"hometeam_shots\",\n",
    "    \"awayteam_shots\",\n",
    "    \"hometeam_shots_on_target\",\n",
    "    \"awayteam_shots_on_target\",\n",
    "    \"hometeam_corners\",\n",
    "    \"awayteam_corners\",\n",
    "    \"hometeam_fouls_done\",\n",
    "    \"awayteam_fouls_done\",\n",
    "    \"hometeam_yellow_cards\",\n",
    "    \"awayteam_yellow_cards\",\n",
    "    \"hometeam_red_cards\",\n",
    "    \"awayteam_red_cards\",\n",
    "    \"B365H\",\n",
    "    \"B365D\",\n",
    "    \"B365A\",\n",
    "    \"BSH\",\n",
    "    \"BSD\",\n",
    "    \"BSA\",\n",
    "    \"BWH\",\n",
    "    \"BWD\",\n",
    "    \"BWA\",\n",
    "    \"GBH\",\n",
    "    \"GBD\",\n",
    "    \"GBA\",\n",
    "    \"IWH\",\n",
    "    \"IWD\",\n",
    "    \"IWA\",\n",
    "    \"LBH\",\n",
    "    \"LBD\",\n",
    "    \"LBA\",\n",
    "    \"PSH\",\n",
    "    \"PSD\",\n",
    "    \"PSA\",\n",
    "    \"SBH\",\n",
    "    \"SBD\",\n",
    "    \"SBA\",\n",
    "    \"SJH\",\n",
    "    \"SJD\",\n",
    "    \"SJA\",\n",
    "    \"VCH\",\n",
    "    \"VCD\",\n",
    "    \"VCA\",\n",
    "    \"WHH\",\n",
    "    \"WHD\",\n",
    "    \"WHA\",\n",
    "]\n",
    "\n",
    "# all elements to make categorical\n",
    "\n",
    "categorical_features = [\n",
    "    \"league\",\n",
    "    \"HomeTeam\",\n",
    "    \"AwayTeam\",\n",
    "    \"full_time_result\",\n",
    "    \"half_time_result\",\n",
    "]\n",
    "integer_features = [\n",
    "    \"full_time_goals_hometeam\",\n",
    "    \"full_time_goals_awayteam\",\n",
    "    \"half_time_goals_hometeam\",\n",
    "    \"half_time_goals_awayteam\",\n",
    "    \"hometeam_shots\",\n",
    "    \"awayteam_shots\",\n",
    "    \"hometeam_shots_on_target\",\n",
    "    \"awayteam_shots_on_target\",\n",
    "    \"hometeam_corners\",\n",
    "    \"awayteam_corners\",\n",
    "    \"hometeam_fouls_done\",\n",
    "    \"awayteam_fouls_done\",\n",
    "    \"hometeam_yellow_cards\",\n",
    "    \"awayteam_yellow_cards\",\n",
    "    \"hometeam_red_cards\",\n",
    "    \"awayteam_red_cards\",\n",
    "]\n",
    "odd_features = [\n",
    "    \"B365H\",\n",
    "    \"B365D\",\n",
    "    \"B365A\",\n",
    "    \"BSH\",\n",
    "    \"BSD\",\n",
    "    \"BSA\",\n",
    "    \"BWH\",\n",
    "    \"BWD\",\n",
    "    \"BWA\",\n",
    "    \"GBH\",\n",
    "    \"GBD\",\n",
    "    \"GBA\",\n",
    "    \"IWH\",\n",
    "    \"IWD\",\n",
    "    \"IWA\",\n",
    "    \"LBH\",\n",
    "    \"LBD\",\n",
    "    \"LBA\",\n",
    "    \"PSH\",\n",
    "    \"PSD\",\n",
    "    \"PSA\",\n",
    "    \"SBH\",\n",
    "    \"SBD\",\n",
    "    \"SBA\",\n",
    "    \"SJH\",\n",
    "    \"SJD\",\n",
    "    \"SJA\",\n",
    "    \"VCH\",\n",
    "    \"VCD\",\n",
    "    \"VCA\",\n",
    "    \"WHH\",\n",
    "    \"WHD\",\n",
    "    \"WHA\",\n",
    "]\n",
    "\n",
    "\n",
    "# all columns with features that are not known on game day\n",
    "not_known_on_game_day = [\n",
    "    \"full_time_goals_hometeam\",\n",
    "    \"full_time_goals_awayteam\",\n",
    "    \"half_time_goals_hometeam\",\n",
    "    \"half_time_goals_awayteam\",\n",
    "    \"half_time_result\",\n",
    "    \"hometeam_shots\",\n",
    "    \"awayteam_shots\",\n",
    "    \"hometeam_shots_on_target\",\n",
    "    \"awayteam_shots_on_target\",\n",
    "    \"hometeam_corners\",\n",
    "    \"awayteam_corners\",\n",
    "    \"hometeam_fouls_done\",\n",
    "    \"awayteam_fouls_done\",\n",
    "    \"hometeam_yellow_cards\",\n",
    "    \"awayteam_yellow_cards\",\n",
    "    \"hometeam_red_cards\",\n",
    "    \"awayteam_red_cards\",\n",
    "    \"HomeTeam_points\",\n",
    "    \"AwayTeam_points\",\n",
    "]\n",
    "odds = [\n",
    "    \"B365H\",\n",
    "    \"B365D\",\n",
    "    \"B365A\",\n",
    "    \"BSH\",\n",
    "    \"BSD\",\n",
    "    \"BSA\",\n",
    "    \"BWH\",\n",
    "    \"BWD\",\n",
    "    \"BWA\",\n",
    "    \"GBH\",\n",
    "    \"GBD\",\n",
    "    \"GBA\",\n",
    "    \"IWH\",\n",
    "    \"IWD\",\n",
    "    \"IWA\",\n",
    "    \"LBH\",\n",
    "    \"LBD\",\n",
    "    \"LBA\",\n",
    "    \"PSH\",\n",
    "    \"PSD\",\n",
    "    \"PSA\",\n",
    "    \"SBH\",\n",
    "    \"SBD\",\n",
    "    \"SBA\",\n",
    "    \"SJH\",\n",
    "    \"SJD\",\n",
    "    \"SJA\",\n",
    "    \"VCH\",\n",
    "    \"VCD\",\n",
    "    \"VCA\",\n",
    "    \"WHH\",\n",
    "    \"WHD\",\n",
    "    \"WHA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_consensus_odds(df, columns_with_odds):\n",
    "    \"\"\"This function computes the consensus odds\n",
    "    Input:\n",
    "        df: dataframe\n",
    "        columns_with_odds: list of columns with the odds\n",
    "    Output:\n",
    "        df: dataframe with the consensus odds added.\n",
    "    \"\"\"\n",
    "    columns_with_odds = [x for x in columns_with_odds if x in list(df.columns)]\n",
    "    home_odd_columns = [col for col in columns_with_odds if col.endswith(\"H\")]\n",
    "    draw_odd_columns = [col for col in columns_with_odds if col.endswith(\"D\")]\n",
    "    away_odd_columns = [col for col in columns_with_odds if col.endswith(\"A\")]\n",
    "\n",
    "    df[\"consensus_odds_home\"] = df[home_odd_columns].mean(axis=1)\n",
    "    df[\"consensus_odds_draw\"] = df[draw_odd_columns].mean(axis=1)\n",
    "    df[\"consensus_odds_away\"] = df[away_odd_columns].mean(axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_indexer_column(data: pd.DataFrame, number_of_folds: int):\n",
    "    n = int(len(data) / number_of_folds)\n",
    "    indexer = []\n",
    "    for i in range(number_of_folds):\n",
    "        indexer.extend([i + 1] * n)\n",
    "    if len(indexer) < len(data):\n",
    "        indexer.extend([number_of_folds] * (len(data) - len(indexer)))\n",
    "    data[\"indexer\"] = indexer\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_test_train_data_per_iteration(i, data_dum, scaler):\n",
    "    data_dum[data_dum[\"indexer\"] <= i]\n",
    "    x_train_subset = data_dum.drop(columns=[\"full_time_result\"], axis=1)\n",
    "    y_train_subset = data_dum[\"full_time_result\"]\n",
    "    test_subset = data_dum[data_dum[\"indexer\"] == i]\n",
    "    y_test_subset = test_subset[\"full_time_result\"]\n",
    "    x_test_subset = data_dum.drop(columns=[\"full_time_result\"], axis=1)\n",
    "    x_train_subset = scaler.fit_transform(x_train_subset)\n",
    "    x_test_subset = scaler.fit_transform(x_test_subset)\n",
    "    return x_train_subset, y_train_subset, x_test_subset, y_test_subset\n",
    "\n",
    "\n",
    "def compute_MAE(y_pred, y_real):\n",
    "    \"\"\"computes the mean right classification rate.\"\"\"\n",
    "    if len(y_pred) != len(y_real):\n",
    "        raise ValueError(\"Arrays must be of the same length\")\n",
    "    result = []\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_real = np.array(y_real)\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y_real[i]:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return 1 - np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_robustness_check(data):\n",
    "    \"\"\"Drop the columns, where all entries are NaN\n",
    "    Input:\n",
    "        data: dataframe\n",
    "    Output:\n",
    "    data: dataframe\n",
    "    .\n",
    "    \"\"\"\n",
    "    data = data.dropna(axis=1, how=\"all\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def compute_percentages_out_of_consensus_odds(df):\n",
    "    \"\"\"This function computes the percentages out of the consensus odds\n",
    "    Input:\n",
    "        df: dataframe\n",
    "        columns_with_consensus_odds: list of columns with the consensus odds\n",
    "    Output:\n",
    "        df: dataframe with the percentages out of the consensus odds added.\n",
    "    \"\"\"\n",
    "    df[\"consensus_percentage_home\"] = 1 / df[\"consensus_odds_home\"]\n",
    "    df[\"consensus_percentage_draw\"] = 1 / df[\"consensus_odds_draw\"]\n",
    "    df[\"consensus_percentage_away\"] = 1 / df[\"consensus_odds_away\"]\n",
    "    df[\"consensus_sum_of_percentages\"] = (\n",
    "        df[\"consensus_percentage_home\"]\n",
    "        + df[\"consensus_percentage_draw\"]\n",
    "        + df[\"consensus_percentage_away\"]\n",
    "    )\n",
    "    df[\"consensus_percentage_home\"] = (\n",
    "        df[\"consensus_percentage_home\"] / df[\"consensus_sum_of_percentages\"]\n",
    "    )\n",
    "    df[\"consensus_percentage_draw\"] = (\n",
    "        df[\"consensus_percentage_draw\"] / df[\"consensus_sum_of_percentages\"]\n",
    "    )\n",
    "    df[\"consensus_percentage_away\"] = (\n",
    "        df[\"consensus_percentage_away\"] / df[\"consensus_sum_of_percentages\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def rolling_forecast_origin_generator(data, min_train_size, horizon):\n",
    "    \"\"\"generates the rolling forecast origin.\"\"\"\n",
    "    for i in range(len(data) - min_train_size - horizon + 1):\n",
    "        split_train = data[: min_train_size + i]\n",
    "        split_test = data[min_train_size + i : min_train_size + i + horizon]\n",
    "        yield split_train, split_test\n",
    "\n",
    "\n",
    "def cross_validation_score(model, cv, metric, y):\n",
    "    \"\"\"computes the cross validation score.\"\"\"\n",
    "    cv_scores = []\n",
    "    for cv_train, cv_test in cv:\n",
    "        model.fit(\n",
    "            cv_train.drop(columns=[\"full_time_result\"]),\n",
    "            y=cv_train[\"full_time_result\"],\n",
    "        )\n",
    "        preds = model.predict(cv_test.drop(columns=[\"full_time_result\"]))\n",
    "        score = metric(y_true=cv_test[\"full_time_result\"], y_pred=preds)\n",
    "        cv_scores.append(score)\n",
    "    return np.array(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning categorical into dummy vars\n",
    "def data_preparation(data, league, not_known_on_game_day, odds):\n",
    "    \"\"\"prepares the data, to be used in the model\n",
    "    Input:\n",
    "        data: dataframe\n",
    "        not_known_on_game_day: list of columns, which are not known on game day\n",
    "        odds: list of columns, which are the odds.\n",
    "\n",
    "    \"\"\"\n",
    "    data = data.drop(columns=\"index\")\n",
    "    data = data.set_index(\"Date\")\n",
    "    data = data.loc[data[\"league\"] == league]\n",
    "    data = compute_consensus_odds(df=data, columns_with_odds=odds)\n",
    "    data = compute_percentages_out_of_consensus_odds(df=data)\n",
    "    odds = data[list(odds)]\n",
    "    data = data.drop(columns=not_known_on_game_day)\n",
    "    data = data.drop(columns=[\"league\", \"kick_off_time\"], axis=1)\n",
    "    data = data.drop(columns=odds, axis=1)\n",
    "    data_dum = pd.get_dummies(data)\n",
    "    data_dum = data_dum.fillna(-33)\n",
    "    data_dum = data_robustness_check(data=data_dum)\n",
    "    return data_dum, odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/Users/luisenriquekaiser/Documents/Final/epp_final_project_sbp/bld/python/data/data_features_added.csv\",\n",
    "    index_col=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum, odds = data_preparation(\n",
    "    data=data,\n",
    "    league=\"E0\",\n",
    "    not_known_on_game_day=not_known_on_game_day,\n",
    "    odds=odds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __best_feature_selection_rfe(scaler, clf, i, data_dum):\n",
    "    \"\"\"computes the best feature selection for Logistic Regression\"\n",
    "    Input:\n",
    "        scaler: MinMaxScaler\n",
    "        clf: LogisticRegression\n",
    "        i: number of features\n",
    "        data_dum: dataframe\n",
    "        Output:\n",
    "        X_train: X_train\n",
    "        Y_train: Y_train.\n",
    "    \"\"\"\n",
    "    rfe = RFE(estimator=clf, n_features_to_select=i, step=1)\n",
    "    X = data_dum.drop(columns=[\"full_time_result\"])\n",
    "    y = data_dum[\"full_time_result\"]\n",
    "    rfe.fit(X, y)\n",
    "    X_temp = rfe.transform(X)\n",
    "    X_train = X_temp[0:3500]\n",
    "    Y_train = y[0:3500]\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    return X_train, Y_train\n",
    "\n",
    "\n",
    "# Creating loop to test which set of features is the best one for Logistic Regression\n",
    "def best_feature_selection_LogisticRegression(data_dum, min_feat, max_feat):\n",
    "    \"\"\"computes the best feature selection for Logistic Regression\n",
    "    Input:\n",
    "        data_dum: dataframe\n",
    "        Output:\n",
    "        acc_results: list of accuracy results\n",
    "        n_features: list of number of features.\n",
    "    \"\"\"\n",
    "    acc_results = []\n",
    "    n_features = []\n",
    "    scaler = MinMaxScaler()\n",
    "    clf = LogisticRegression(max_iter=1000, multi_class=\"multinomial\")\n",
    "\n",
    "    for i in range(min_feat, max_feat):\n",
    "        X_train, Y_train = __best_feature_selection_rfe(\n",
    "            scaler=scaler,\n",
    "            clf=clf,\n",
    "            i=i,\n",
    "            data_dum=data_dum,\n",
    "        )\n",
    "        scores = cross_val_score(clf, X_train, Y_train, scoring=\"accuracy\", cv=5)\n",
    "        acc_results.append(scores.mean())\n",
    "        n_features.append(i)\n",
    "    return acc_results, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_results, n_features = best_feature_selection_LogisticRegression(\n",
    "    data_dum=data_dum,\n",
    "    min_feat=3,\n",
    "    max_feat=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_results\n",
    "## 11 min pro feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_features, acc_results)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"N features\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# getting the best 13 features from RFE\n",
    "rfe = RFE(estimator=clf, n_features_to_select=13, step=1)\n",
    "rfe.fit(X, y)\n",
    "X_transformed = rfe.transform(X)\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "\n",
    "cv_rolling = rolling_forecast_origin_generator(\n",
    "    data=data_dum,\n",
    "    min_train_size=400,\n",
    "    horizon=50,\n",
    ")\n",
    "cv_scores1 = cross_validation_score(\n",
    "    model=logisticRegr,\n",
    "    cv=cv_rolling,\n",
    "    metric=balanced_accuracy_score,\n",
    "    y=\"full_time_result\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum.to_excel(\"datasandbox.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
