{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all information needed to scrape data from football-data.co.uk\n",
    "\n",
    "beginning_url = \"https://www.football-data.co.uk/\"\n",
    "years = [\n",
    "    \"2223\",\n",
    "    \"2122\",\n",
    "    \"2021\",\n",
    "    \"1920\",\n",
    "    \"1819\",\n",
    "    \"1718\",\n",
    "    \"1617\",\n",
    "    \"1516\",\n",
    "    \"1415\",\n",
    "    \"1314\",\n",
    "    \"1213\",\n",
    "    \"1213\",\n",
    "    \"1112\",\n",
    "]\n",
    "Leagues = {\n",
    "    \"PL\": {\n",
    "        \"Foldername\": \"PL_data\",\n",
    "        \"Leaguetag\": \"PL\",\n",
    "        \"Leaguename\": \"E0\",\n",
    "        \"Leagueurl\": \"https://www.football-data.co.uk/englandm.php\",\n",
    "    },\n",
    "    \"BL\": {\n",
    "        \"Foldername\": \"BL_data\",\n",
    "        \"Leaguetag\": \"BL\",\n",
    "        \"Leaguename\": \"D1\",\n",
    "        \"Leagueurl\": \"https://www.football-data.co.uk/germanym.php\",\n",
    "    },\n",
    "    \"PD\": {\n",
    "        \"Foldername\": \"PD_data\",\n",
    "        \"Leaguetag\": \"PD\",\n",
    "        \"Leaguename\": \"SP1\",\n",
    "        \"Leagueurl\": \"https://www.football-data.co.uk/spainm.php\",\n",
    "    },\n",
    "    \"SA\": {\n",
    "        \"Foldername\": \"SA_data\",\n",
    "        \"Leaguetag\": \"SA\",\n",
    "        \"Leaguename\": \"I1\",\n",
    "        \"Leagueurl\": \"https://www.football-data.co.uk/italym.php\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "considered_features = [\n",
    "    \"league\",\n",
    "    \"kick_off_time\",\n",
    "    \"HomeTeam\",\n",
    "    \"AwayTeam\",\n",
    "    \"full_time_goals_hometeam\",\n",
    "    \"full_time_goals_awayteam\",\n",
    "    \"full_time_result\",\n",
    "    \"half_time_goals_hometeam\",\n",
    "    \"half_time_goals_awayteam\",\n",
    "    \"half_time_result\",\n",
    "    \"hometeam_shots\",\n",
    "    \"awayteam_shots\",\n",
    "    \"hometeam_shots_on_target\",\n",
    "    \"awayteam_shots_on_target\",\n",
    "    \"hometeam_corners\",\n",
    "    \"awayteam_corners\",\n",
    "    \"hometeam_fouls_done\",\n",
    "    \"awayteam_fouls_done\",\n",
    "    \"hometeam_yellow_cards\",\n",
    "    \"awayteam_yellow_cards\",\n",
    "    \"hometeam_red_cards\",\n",
    "    \"awayteam_red_cards\",\n",
    "    \"B365H\",\n",
    "    \"B365D\",\n",
    "    \"B365A\",\n",
    "    \"BSH\",\n",
    "    \"BSD\",\n",
    "    \"BSA\",\n",
    "    \"BWH\",\n",
    "    \"BWD\",\n",
    "    \"BWA\",\n",
    "    \"GBH\",\n",
    "    \"GBD\",\n",
    "    \"GBA\",\n",
    "    \"IWH\",\n",
    "    \"IWD\",\n",
    "    \"IWA\",\n",
    "    \"LBH\",\n",
    "    \"LBD\",\n",
    "    \"LBA\",\n",
    "    \"PSH\",\n",
    "    \"PSD\",\n",
    "    \"PSA\",\n",
    "    \"SBH\",\n",
    "    \"SBD\",\n",
    "    \"SBA\",\n",
    "    \"SJH\",\n",
    "    \"SJD\",\n",
    "    \"SJA\",\n",
    "    \"VCH\",\n",
    "    \"VCD\",\n",
    "    \"VCA\",\n",
    "    \"WHH\",\n",
    "    \"WHD\",\n",
    "    \"WHA\",\n",
    "]\n",
    "\n",
    "# all elements to make categorical\n",
    "\n",
    "categorical_features = [\n",
    "    \"league\",\n",
    "    \"HomeTeam\",\n",
    "    \"AwayTeam\",\n",
    "    \"full_time_result\",\n",
    "    \"half_time_result\",\n",
    "]\n",
    "integer_features = [\n",
    "    \"full_time_goals_hometeam\",\n",
    "    \"full_time_goals_awayteam\",\n",
    "    \"half_time_goals_hometeam\",\n",
    "    \"half_time_goals_awayteam\",\n",
    "    \"hometeam_shots\",\n",
    "    \"awayteam_shots\",\n",
    "    \"hometeam_shots_on_target\",\n",
    "    \"awayteam_shots_on_target\",\n",
    "    \"hometeam_corners\",\n",
    "    \"awayteam_corners\",\n",
    "    \"hometeam_fouls_done\",\n",
    "    \"awayteam_fouls_done\",\n",
    "    \"hometeam_yellow_cards\",\n",
    "    \"awayteam_yellow_cards\",\n",
    "    \"hometeam_red_cards\",\n",
    "    \"awayteam_red_cards\",\n",
    "]\n",
    "odd_features = [\n",
    "    \"B365H\",\n",
    "    \"B365D\",\n",
    "    \"B365A\",\n",
    "    \"BSH\",\n",
    "    \"BSD\",\n",
    "    \"BSA\",\n",
    "    \"BWH\",\n",
    "    \"BWD\",\n",
    "    \"BWA\",\n",
    "    \"GBH\",\n",
    "    \"GBD\",\n",
    "    \"GBA\",\n",
    "    \"IWH\",\n",
    "    \"IWD\",\n",
    "    \"IWA\",\n",
    "    \"LBH\",\n",
    "    \"LBD\",\n",
    "    \"LBA\",\n",
    "    \"PSH\",\n",
    "    \"PSD\",\n",
    "    \"PSA\",\n",
    "    \"SBH\",\n",
    "    \"SBD\",\n",
    "    \"SBA\",\n",
    "    \"SJH\",\n",
    "    \"SJD\",\n",
    "    \"SJA\",\n",
    "    \"VCH\",\n",
    "    \"VCD\",\n",
    "    \"VCA\",\n",
    "    \"WHH\",\n",
    "    \"WHD\",\n",
    "    \"WHA\",\n",
    "]\n",
    "\n",
    "\n",
    "# all columns with features that are not known on game day\n",
    "not_known_on_game_day = [\n",
    "    \"full_time_goals_hometeam\",\n",
    "    \"full_time_goals_awayteam\",\n",
    "    \"half_time_goals_hometeam\",\n",
    "    \"half_time_goals_awayteam\",\n",
    "    \"half_time_result\",\n",
    "    \"hometeam_shots\",\n",
    "    \"awayteam_shots\",\n",
    "    \"hometeam_shots_on_target\",\n",
    "    \"awayteam_shots_on_target\",\n",
    "    \"hometeam_corners\",\n",
    "    \"awayteam_corners\",\n",
    "    \"hometeam_fouls_done\",\n",
    "    \"awayteam_fouls_done\",\n",
    "    \"hometeam_yellow_cards\",\n",
    "    \"awayteam_yellow_cards\",\n",
    "    \"hometeam_red_cards\",\n",
    "    \"awayteam_red_cards\",\n",
    "    \"HomeTeam_points\",\n",
    "    \"AwayTeam_points\",\n",
    "]\n",
    "odds = [\n",
    "    \"B365H\",\n",
    "    \"B365D\",\n",
    "    \"B365A\",\n",
    "    \"BSH\",\n",
    "    \"BSD\",\n",
    "    \"BSA\",\n",
    "    \"BWH\",\n",
    "    \"BWD\",\n",
    "    \"BWA\",\n",
    "    \"GBH\",\n",
    "    \"GBD\",\n",
    "    \"GBA\",\n",
    "    \"IWH\",\n",
    "    \"IWD\",\n",
    "    \"IWA\",\n",
    "    \"LBH\",\n",
    "    \"LBD\",\n",
    "    \"LBA\",\n",
    "    \"PSH\",\n",
    "    \"PSD\",\n",
    "    \"PSA\",\n",
    "    \"SBH\",\n",
    "    \"SBD\",\n",
    "    \"SBA\",\n",
    "    \"SJH\",\n",
    "    \"SJD\",\n",
    "    \"SJA\",\n",
    "    \"VCH\",\n",
    "    \"VCD\",\n",
    "    \"VCA\",\n",
    "    \"WHH\",\n",
    "    \"WHD\",\n",
    "    \"WHA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_consensus_odds(df, columns_with_odds):\n",
    "    \"\"\"This function computes the consensus odds\n",
    "    Input:\n",
    "        df: dataframe\n",
    "        columns_with_odds: list of columns with the odds\n",
    "    Output:\n",
    "        df: dataframe with the consensus odds added.\n",
    "    \"\"\"\n",
    "    columns_with_odds = [x for x in columns_with_odds if x in list(df.columns)]\n",
    "    home_odd_columns = [col for col in columns_with_odds if col.endswith(\"H\")]\n",
    "    draw_odd_columns = [col for col in columns_with_odds if col.endswith(\"D\")]\n",
    "    away_odd_columns = [col for col in columns_with_odds if col.endswith(\"A\")]\n",
    "    df[\"consensus_odds_home\"] = df[home_odd_columns].mean(axis=1)\n",
    "    df[\"consensus_odds_draw\"] = df[draw_odd_columns].mean(axis=1)\n",
    "    df[\"consensus_odds_away\"] = df[away_odd_columns].mean(axis=1)\n",
    "    return df, df.columns\n",
    "\n",
    "\n",
    "def add_indexer_column(data: pd.DataFrame, number_of_folds: int):\n",
    "    n = int(len(data) / number_of_folds)\n",
    "    indexer = []\n",
    "    for i in range(number_of_folds):\n",
    "        indexer.extend([i + 1] * n)\n",
    "    if len(indexer) < len(data):\n",
    "        indexer.extend([number_of_folds] * (len(data) - len(indexer)))\n",
    "    data[\"indexer\"] = indexer\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_test_train_data_per_iteration(i, data_dum, scaler):\n",
    "    data_dum[data_dum[\"indexer\"] <= i]\n",
    "    x_train_subset = data_dum.drop(columns=[\"full_time_result\"], axis=1)\n",
    "    y_train_subset = data_dum[\"full_time_result\"]\n",
    "    test_subset = data_dum[data_dum[\"indexer\"] == i]\n",
    "    y_test_subset = test_subset[\"full_time_result\"]\n",
    "    x_test_subset = data_dum.drop(columns=[\"full_time_result\"], axis=1)\n",
    "    x_train_subset = scaler.fit_transform(x_train_subset)\n",
    "    x_test_subset = scaler.fit_transform(x_test_subset)\n",
    "    return x_train_subset, y_train_subset, x_test_subset, y_test_subset\n",
    "\n",
    "\n",
    "def compute_MAE(y_pred, y_real):\n",
    "    \"\"\"computes the mean right classification rate.\"\"\"\n",
    "    if len(y_pred) != len(y_real):\n",
    "        raise ValueError(\"Arrays must be of the same length\")\n",
    "    result = []\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_real = np.array(y_real)\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y_real[i]:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return 1 - np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_robustness_check(data):\n",
    "    \"\"\"Drop the columns, where all entries are NaN\n",
    "    Input:\n",
    "        data: dataframe\n",
    "    Output:\n",
    "    data: dataframe\n",
    "    .\n",
    "    \"\"\"\n",
    "    data = data.dropna(axis=1, how=\"all\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def compute_percentages_out_of_consensus_odds(df):\n",
    "    \"\"\"This function computes the percentages out of the consensus odds\n",
    "    Input:\n",
    "        df: dataframe\n",
    "        columns_with_consensus_odds: list of columns with the consensus odds\n",
    "    Output:\n",
    "        df: dataframe with the percentages out of the consensus odds added.\n",
    "    \"\"\"\n",
    "    df[\"consensus_percentage_home\"] = 1 / df[\"consensus_odds_home\"]\n",
    "    df[\"consensus_percentage_draw\"] = 1 / df[\"consensus_odds_draw\"]\n",
    "    df[\"consensus_percentage_away\"] = 1 / df[\"consensus_odds_away\"]\n",
    "    df[\"consensus_sum_of_percentages\"] = (\n",
    "        df[\"consensus_percentage_home\"]\n",
    "        + df[\"consensus_percentage_draw\"]\n",
    "        + df[\"consensus_percentage_away\"]\n",
    "    )\n",
    "    df[\"consensus_percentage_home\"] = (\n",
    "        df[\"consensus_percentage_home\"] / df[\"consensus_sum_of_percentages\"]\n",
    "    )\n",
    "    df[\"consensus_percentage_draw\"] = (\n",
    "        df[\"consensus_percentage_draw\"] / df[\"consensus_sum_of_percentages\"]\n",
    "    )\n",
    "    df[\"consensus_percentage_away\"] = (\n",
    "        df[\"consensus_percentage_away\"] / df[\"consensus_sum_of_percentages\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def rolling_forecast_origin_generator(data, min_train_size, horizon):\n",
    "    \"\"\"generates the rolling forecast origin.\"\"\"\n",
    "    for i in range(len(data) - min_train_size - horizon + 1):\n",
    "        split_train = data[: min_train_size + i]\n",
    "        split_test = data[min_train_size + i : min_train_size + i + horizon]\n",
    "        yield split_train, split_test\n",
    "\n",
    "\n",
    "def cross_validation_score(model, cv, metric, y):\n",
    "    \"\"\"computes the cross validation score.\"\"\"\n",
    "    cv_scores = []\n",
    "    for cv_train, cv_test in cv:\n",
    "        model.fit(\n",
    "            cv_train.drop(columns=[\"full_time_result\"]),\n",
    "            y=cv_train[\"full_time_result\"],\n",
    "        )\n",
    "        preds = model.predict(cv_test.drop(columns=[\"full_time_result\"]))\n",
    "        score = metric(y_true=cv_test[\"full_time_result\"], y_pred=preds)\n",
    "        cv_scores.append(score)\n",
    "    return np.array(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    \"/Users/luisenriquekaiser/Documents/Final/epp_final_project_sbp/bld/python/data/data_features_added.csv\",\n",
    "    index_col=False,\n",
    ")\n",
    "data = data.drop(columns=\"index\")\n",
    "number_of_folds = 40\n",
    "# drop all columns, with information not present at game start\n",
    "data = data.sort_values(by=\"Date\")\n",
    "data = data.set_index(\"Date\")  #\n",
    "data, columns_with_odds = compute_consensus_odds(df=data, columns_with_odds=odds)\n",
    "data = compute_percentages_out_of_consensus_odds(df=data)\n",
    "\n",
    "# just for now, in the final one I want to have a loop doing all of this\n",
    "data = data.loc[data[\"league\"] == \"E0\"]\n",
    "\n",
    "league = \"E0\"\n",
    "# turning the target variable into integers\n",
    "data[\"full_time_result\"] = np.where(\n",
    "    data.full_time_result == \"H\",\n",
    "    2,\n",
    "    np.where(data.full_time_result == \"A\", 1, 0),\n",
    ")\n",
    "data = data.drop(columns=not_known_on_game_day)\n",
    "# filling NAs\n",
    "data = data.fillna(np.nan)\n",
    "odds = data[list(odds)]\n",
    "data = data.drop(columns=odds, axis=1)\n",
    "data = data.drop(columns=[\"league\", \"kick_off_time\"], axis=1)\n",
    "# turning categorical into dummy vars\n",
    "data_dum = pd.get_dummies(data)\n",
    "data_dum = data_dum.fillna(-33)\n",
    "data_dum = data_robustness_check(data=data_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 500, num=5)]\n",
    "max_depth.append(None)\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Create the random grid\n",
    "random_grid = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"max_depth\": max_depth,\n",
    "    \"bootstrap\": bootstrap,\n",
    "}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_dum.drop(columns=[\"full_time_result\"])\n",
    "y = data_dum[\"full_time_result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rf_model_grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=random_grid,\n",
    "    cv=tscv,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=-2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"/Users/luisenriquekaiser/Documents/Final/epp_final_project_sbp/bld/python/models/final_model_E0.pkl\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
